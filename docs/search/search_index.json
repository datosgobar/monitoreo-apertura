{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Indice Monitoreo Apertura Monitoreo Apertura Versi\u00f3n : 0.0.44 Monitoreo Apertura es un desarrollo de la Administraci\u00f3n P\u00fablica Nacional que utiliza el framework Django para organizar una serie de m\u00f3dulos con funciones que permiten administrar, monitorear y configurar reportes de seguimiento de la red de nodos de datos abiertos.","title":"Inicio"},{"location":"#indice","text":"Monitoreo Apertura","title":"Indice"},{"location":"#monitoreo-apertura","text":"Versi\u00f3n : 0.0.44 Monitoreo Apertura es un desarrollo de la Administraci\u00f3n P\u00fablica Nacional que utiliza el framework Django para organizar una serie de m\u00f3dulos con funciones que permiten administrar, monitorear y configurar reportes de seguimiento de la red de nodos de datos abiertos.","title":"Monitoreo Apertura"},{"location":"HISTORY/","text":"Indice Versiones 0.0.44 (11-06-19) 0.0.43 (04-06-19) 0.0.42 (29-05-19) 0.0.41 (22-05-19) 0.0.40 (14-05-19) 0.0.39 (16-04-19) 0.0.38 (16-04-19) 0.0.37 (15-04-19) 0.0.36 (15-04-19) 0.0.35 (04-04-19) 0.0.34 (01-03-19) 0.0.33 (01-03-19) 0.0.32 (19-02-19) 0.0.31 (05-02-19) 0.0.30 (17-01-19) 0.0.29 (16-01-19) 0.0.28 (21-12-18) 0.0.27 (11-12-18) 0.0.26 (4-12-18) 0.0.25 (28-11-18) 0.0.24 (05-11-18) 0.0.23 (23-10-18) 0.0.22 (11-10-18) 0.0.22-prod (11-10-18) 0.0.21 (11-10-18) 0.0.20 (8-10-18) 0.0.19 (5-10-18) 0.0.18 (19-09-18) 0.0.17 (13-09-18) 0.0.16 (5-09-18) 0.0.15 (4-09-18) 0.0.14 (29-08-18) 0.0.12 (07-08-18) 0.0.11 (03-08-18) 0.0.10 (26-07-18) 0.0.9 (23-07-18) 0.0.8 (20-07-18) 0.0.7 (18-07-18) 0.0.6 (12-07-18) 0.0.5 (04-07-18) 0.0.4 (02-07-18) 0.0.3 (19-06-18) 0.0.2 (13-06-18) 0.0.1 (13-06-18) Versiones 1.0.1 (06-08-19) Bump de django-datajsonar a 0.4.3 1.0.0 (11-07-19) Primer release considerado estable 0.0.44 (11-06-19) Actualiza versi\u00f3n de django_datajsonar Agrega endpoint de /nodos-red-indicadores.csv 0.0.43 (04-06-19) Actualiza versiones de pydatajson y django_datajsonar 0.0.42 (29-05-19) Overridea la funci\u00f3n de import de indicadores para usar una asincr\u00f3nica 0.0.41 (22-05-19) Actualiza version de django_datajsonar para agregar la ruta nodes.csv y nodos.csv Agrega adem\u00e1s el campo landingPage al admin de dataset 0.0.40 (14-05-19) Actualiza version de django_datajsonar para agregar la ruta nodes.json 0.0.39 (16-04-19) Actualiza version de pydatajson 0.0.38 (16-04-19) Actualiza y corrige logueo de sentry 0.0.37 (15-04-19) Actualiza versi\u00f3n de django-datajsonar Agrega management command para importar/exportar csv de indicadores 0.0.36 (15-04-19) Actualiza versi\u00f3n de pydatajson 0.0.35 (04-04-19) Ordena las columnas de los csv de series de tiempo Revisi\u00f3n de nombres Fix del campo from en los mails Port a python 3 Actualiza versi\u00f3n de pydatajson y django_datajsonar 0.0.34 (01-03-19) Reordena apps del admin 0.0.33 (01-03-19) Cambia el horario de mantenimiento a las 00:00 Reutiliza las conexiones smtp para el env\u00edo de reportes Actualiza versi\u00f3n de pydatajson y django_datajsonar 0.0.32 (19-02-19) Actualiza versi\u00f3n de pydatajson y django_datajsonar Revis\u00f3n de nombres y refactor del admin Aseguro la existencia de un upkeep job para los synchronizers 0.0.31 (05-02-19) Actualiza versi\u00f3n de django_datajsonar Fix a la recolecci\u00f3n de indicadores de nodos federadores Restart de los workers en deploy 0.0.30 (17-01-19) Actualiza versi\u00f3n de pydatajson 0.0.29 (16-01-19) Singleton para modelo central Reportes de error cuando no se puede parsear un cat\u00e1logo Actualiza versi\u00f3n de pydatajson y django_datajsonar 0.0.28 (21-12-18) Nuevos modelo indicadores federadores. Series sobre los indicadores de los nodos federadores. Agrega logs del task de indicadores al reporte de staff. Actualiza versi\u00f3n de pydatajson. 0.0.27 (11-12-18) Agrega management command para importar indicadores de un csv. 0.0.26 (4-12-18) Agrega series de tiempo para indicadores de red y de nodos ( admin/indicadorred/series-indicadores y admin/indicador/<id de catalogo>/series-indicadores respectivamente) 0.0.25 (28-11-18) Agrega reportes de validaci\u00f3n para los nodos de la red 0.0.24 (05-11-18) Actualiza versi\u00f3n de pydatajson y django_datajsonar. Agrega documentaci\u00f3n de synchronizers y config files. 0.0.23 (23-10-18) Bugfix en reportes que llegaban vac\u00edos. 0.0.22 (11-10-18) Actualiza versi\u00f3n de pydatajson y django_datajsonar (Incluye los synchronizers). 0.0.22-prod (11-10-18) Actualiza versi\u00f3n de pydatajson (No incluye los synchronizers). 0.0.21 (11-10-18) En el command para borrar duplicados, me quedo con el \u00faltimo registrado. Separa las tareas en queues para hacer uso de los sincronizadores. Actualiza versi\u00f3n de django_datajsonar. 0.0.20 (8-10-18) Fix en el deploy de rqscheduler. 0.0.19 (5-10-18) Actualiza versi\u00f3n de django_datajsonar. Actualiza versi\u00f3n de pydatajson. Bugfix de generaci\u00f3n de indicadores duplicados. 0.0.18 (19-09-18) Actualiza versi\u00f3n de django_datajsonar. 0.0.17 (13-09-18) Bugfix en el schedule form de reportes. Bugfix en la creaci\u00f3n de corridas de federaci\u00f3n. 0.0.16 (5-09-18) Actualiza versi\u00f3n de pydatajson. 0.0.15 (4-09-18) Management command para programar tareas default. Form para simplificar la programaci\u00f3n de tareas peri\u00f3dicas. 0.0.14 (29-08-18) Actualiza versi\u00f3n de pydatajson. 0.0.12 (07-08-18) Saca temporalmente acciones de top y bottom para los tipos de indicadores. 0.0.11 (03-08-18) Agrega secci\u00f3n de resumen al reporte de indicadores. Permite ordenar los indicadores en el reporte. Permite ocultar indicadores del reporte. Ordena los indicadores no num\u00e9ricos por valor de manera descendiente. 0.0.10 (26-07-18) Ahora es posible disparar la tarea de generaci\u00f3n de reportes desde el admin de django, creando un ReportGenerationTask . 0.0.9 (23-07-18) Funcionalidad de mail de reporte de la red de nodos para los administradores de nodos. 0.0.8 (20-07-18) Funcionalidad de mail de reporte de la red de nodos para usuarios staff. 0.0.7 (18-07-18) Fix de timezones Migraci\u00f3n para indicadores con ids faltantes. Usa nueva versi\u00f3n de django datajsonar con columna reviewed para datasets. 0.0.6 (12-07-18) Agrega id de nodos a los indicadores. Genera los indicadores de red a partir de los nodos indexables. Actualiza la versi\u00f3n de pydatajson para calcular los 3 nuevos indicadores. 0.0.5 (04-07-18) Agrega help text de url de nodos (tag para probar el deploy). 0.0.4 (02-07-18) Modelado de corridas de indicadores. Posibilidad de correr calculos de indicadores desde la UI. Descarga de datasets config files. Se dispara una corrida de federaci\u00f3n al guardar un FederationTask desde la UI. Logueo de errores de federaci\u00f3n y validaci\u00f3n en FederationTask. 0.0.3 (19-06-18) Fijar versi\u00f3n de pydatajson . Arreglos en migraciones. 0.0.2 (13-06-18) Arreglos para CD en staging. 0.0.1 (13-06-18) Incorporaci\u00f3n de django_datajsonar con la posibilidad de modelar la red de nodos. Modelado de los nodos federadores y corridas de federaci\u00f3n. Posibilidad de correr federaciones desde la UI.","title":"Historial de versiones"},{"location":"HISTORY/#indice","text":"Versiones 0.0.44 (11-06-19) 0.0.43 (04-06-19) 0.0.42 (29-05-19) 0.0.41 (22-05-19) 0.0.40 (14-05-19) 0.0.39 (16-04-19) 0.0.38 (16-04-19) 0.0.37 (15-04-19) 0.0.36 (15-04-19) 0.0.35 (04-04-19) 0.0.34 (01-03-19) 0.0.33 (01-03-19) 0.0.32 (19-02-19) 0.0.31 (05-02-19) 0.0.30 (17-01-19) 0.0.29 (16-01-19) 0.0.28 (21-12-18) 0.0.27 (11-12-18) 0.0.26 (4-12-18) 0.0.25 (28-11-18) 0.0.24 (05-11-18) 0.0.23 (23-10-18) 0.0.22 (11-10-18) 0.0.22-prod (11-10-18) 0.0.21 (11-10-18) 0.0.20 (8-10-18) 0.0.19 (5-10-18) 0.0.18 (19-09-18) 0.0.17 (13-09-18) 0.0.16 (5-09-18) 0.0.15 (4-09-18) 0.0.14 (29-08-18) 0.0.12 (07-08-18) 0.0.11 (03-08-18) 0.0.10 (26-07-18) 0.0.9 (23-07-18) 0.0.8 (20-07-18) 0.0.7 (18-07-18) 0.0.6 (12-07-18) 0.0.5 (04-07-18) 0.0.4 (02-07-18) 0.0.3 (19-06-18) 0.0.2 (13-06-18) 0.0.1 (13-06-18)","title":"Indice"},{"location":"HISTORY/#versiones","text":"","title":"Versiones"},{"location":"HISTORY/#101-06-08-19","text":"Bump de django-datajsonar a 0.4.3","title":"1.0.1 (06-08-19)"},{"location":"HISTORY/#100-11-07-19","text":"Primer release considerado estable","title":"1.0.0 (11-07-19)"},{"location":"HISTORY/#0044-11-06-19","text":"Actualiza versi\u00f3n de django_datajsonar Agrega endpoint de /nodos-red-indicadores.csv","title":"0.0.44 (11-06-19)"},{"location":"HISTORY/#0043-04-06-19","text":"Actualiza versiones de pydatajson y django_datajsonar","title":"0.0.43 (04-06-19)"},{"location":"HISTORY/#0042-29-05-19","text":"Overridea la funci\u00f3n de import de indicadores para usar una asincr\u00f3nica","title":"0.0.42 (29-05-19)"},{"location":"HISTORY/#0041-22-05-19","text":"Actualiza version de django_datajsonar para agregar la ruta nodes.csv y nodos.csv Agrega adem\u00e1s el campo landingPage al admin de dataset","title":"0.0.41 (22-05-19)"},{"location":"HISTORY/#0040-14-05-19","text":"Actualiza version de django_datajsonar para agregar la ruta nodes.json","title":"0.0.40 (14-05-19)"},{"location":"HISTORY/#0039-16-04-19","text":"Actualiza version de pydatajson","title":"0.0.39 (16-04-19)"},{"location":"HISTORY/#0038-16-04-19","text":"Actualiza y corrige logueo de sentry","title":"0.0.38 (16-04-19)"},{"location":"HISTORY/#0037-15-04-19","text":"Actualiza versi\u00f3n de django-datajsonar Agrega management command para importar/exportar csv de indicadores","title":"0.0.37 (15-04-19)"},{"location":"HISTORY/#0036-15-04-19","text":"Actualiza versi\u00f3n de pydatajson","title":"0.0.36 (15-04-19)"},{"location":"HISTORY/#0035-04-04-19","text":"Ordena las columnas de los csv de series de tiempo Revisi\u00f3n de nombres Fix del campo from en los mails Port a python 3 Actualiza versi\u00f3n de pydatajson y django_datajsonar","title":"0.0.35 (04-04-19)"},{"location":"HISTORY/#0034-01-03-19","text":"Reordena apps del admin","title":"0.0.34 (01-03-19)"},{"location":"HISTORY/#0033-01-03-19","text":"Cambia el horario de mantenimiento a las 00:00 Reutiliza las conexiones smtp para el env\u00edo de reportes Actualiza versi\u00f3n de pydatajson y django_datajsonar","title":"0.0.33 (01-03-19)"},{"location":"HISTORY/#0032-19-02-19","text":"Actualiza versi\u00f3n de pydatajson y django_datajsonar Revis\u00f3n de nombres y refactor del admin Aseguro la existencia de un upkeep job para los synchronizers","title":"0.0.32 (19-02-19)"},{"location":"HISTORY/#0031-05-02-19","text":"Actualiza versi\u00f3n de django_datajsonar Fix a la recolecci\u00f3n de indicadores de nodos federadores Restart de los workers en deploy","title":"0.0.31 (05-02-19)"},{"location":"HISTORY/#0030-17-01-19","text":"Actualiza versi\u00f3n de pydatajson","title":"0.0.30 (17-01-19)"},{"location":"HISTORY/#0029-16-01-19","text":"Singleton para modelo central Reportes de error cuando no se puede parsear un cat\u00e1logo Actualiza versi\u00f3n de pydatajson y django_datajsonar","title":"0.0.29 (16-01-19)"},{"location":"HISTORY/#0028-21-12-18","text":"Nuevos modelo indicadores federadores. Series sobre los indicadores de los nodos federadores. Agrega logs del task de indicadores al reporte de staff. Actualiza versi\u00f3n de pydatajson.","title":"0.0.28 (21-12-18)"},{"location":"HISTORY/#0027-11-12-18","text":"Agrega management command para importar indicadores de un csv.","title":"0.0.27 (11-12-18)"},{"location":"HISTORY/#0026-4-12-18","text":"Agrega series de tiempo para indicadores de red y de nodos ( admin/indicadorred/series-indicadores y admin/indicador/<id de catalogo>/series-indicadores respectivamente)","title":"0.0.26 (4-12-18)"},{"location":"HISTORY/#0025-28-11-18","text":"Agrega reportes de validaci\u00f3n para los nodos de la red","title":"0.0.25 (28-11-18)"},{"location":"HISTORY/#0024-05-11-18","text":"Actualiza versi\u00f3n de pydatajson y django_datajsonar. Agrega documentaci\u00f3n de synchronizers y config files.","title":"0.0.24 (05-11-18)"},{"location":"HISTORY/#0023-23-10-18","text":"Bugfix en reportes que llegaban vac\u00edos.","title":"0.0.23 (23-10-18)"},{"location":"HISTORY/#0022-11-10-18","text":"Actualiza versi\u00f3n de pydatajson y django_datajsonar (Incluye los synchronizers).","title":"0.0.22 (11-10-18)"},{"location":"HISTORY/#0022-prod-11-10-18","text":"Actualiza versi\u00f3n de pydatajson (No incluye los synchronizers).","title":"0.0.22-prod (11-10-18)"},{"location":"HISTORY/#0021-11-10-18","text":"En el command para borrar duplicados, me quedo con el \u00faltimo registrado. Separa las tareas en queues para hacer uso de los sincronizadores. Actualiza versi\u00f3n de django_datajsonar.","title":"0.0.21 (11-10-18)"},{"location":"HISTORY/#0020-8-10-18","text":"Fix en el deploy de rqscheduler.","title":"0.0.20 (8-10-18)"},{"location":"HISTORY/#0019-5-10-18","text":"Actualiza versi\u00f3n de django_datajsonar. Actualiza versi\u00f3n de pydatajson. Bugfix de generaci\u00f3n de indicadores duplicados.","title":"0.0.19 (5-10-18)"},{"location":"HISTORY/#0018-19-09-18","text":"Actualiza versi\u00f3n de django_datajsonar.","title":"0.0.18 (19-09-18)"},{"location":"HISTORY/#0017-13-09-18","text":"Bugfix en el schedule form de reportes. Bugfix en la creaci\u00f3n de corridas de federaci\u00f3n.","title":"0.0.17 (13-09-18)"},{"location":"HISTORY/#0016-5-09-18","text":"Actualiza versi\u00f3n de pydatajson.","title":"0.0.16 (5-09-18)"},{"location":"HISTORY/#0015-4-09-18","text":"Management command para programar tareas default. Form para simplificar la programaci\u00f3n de tareas peri\u00f3dicas.","title":"0.0.15 (4-09-18)"},{"location":"HISTORY/#0014-29-08-18","text":"Actualiza versi\u00f3n de pydatajson.","title":"0.0.14 (29-08-18)"},{"location":"HISTORY/#0012-07-08-18","text":"Saca temporalmente acciones de top y bottom para los tipos de indicadores.","title":"0.0.12 (07-08-18)"},{"location":"HISTORY/#0011-03-08-18","text":"Agrega secci\u00f3n de resumen al reporte de indicadores. Permite ordenar los indicadores en el reporte. Permite ocultar indicadores del reporte. Ordena los indicadores no num\u00e9ricos por valor de manera descendiente.","title":"0.0.11 (03-08-18)"},{"location":"HISTORY/#0010-26-07-18","text":"Ahora es posible disparar la tarea de generaci\u00f3n de reportes desde el admin de django, creando un ReportGenerationTask .","title":"0.0.10 (26-07-18)"},{"location":"HISTORY/#009-23-07-18","text":"Funcionalidad de mail de reporte de la red de nodos para los administradores de nodos.","title":"0.0.9 (23-07-18)"},{"location":"HISTORY/#008-20-07-18","text":"Funcionalidad de mail de reporte de la red de nodos para usuarios staff.","title":"0.0.8 (20-07-18)"},{"location":"HISTORY/#007-18-07-18","text":"Fix de timezones Migraci\u00f3n para indicadores con ids faltantes. Usa nueva versi\u00f3n de django datajsonar con columna reviewed para datasets.","title":"0.0.7 (18-07-18)"},{"location":"HISTORY/#006-12-07-18","text":"Agrega id de nodos a los indicadores. Genera los indicadores de red a partir de los nodos indexables. Actualiza la versi\u00f3n de pydatajson para calcular los 3 nuevos indicadores.","title":"0.0.6 (12-07-18)"},{"location":"HISTORY/#005-04-07-18","text":"Agrega help text de url de nodos (tag para probar el deploy).","title":"0.0.5 (04-07-18)"},{"location":"HISTORY/#004-02-07-18","text":"Modelado de corridas de indicadores. Posibilidad de correr calculos de indicadores desde la UI. Descarga de datasets config files. Se dispara una corrida de federaci\u00f3n al guardar un FederationTask desde la UI. Logueo de errores de federaci\u00f3n y validaci\u00f3n en FederationTask.","title":"0.0.4 (02-07-18)"},{"location":"HISTORY/#003-19-06-18","text":"Fijar versi\u00f3n de pydatajson . Arreglos en migraciones.","title":"0.0.3 (19-06-18)"},{"location":"HISTORY/#002-13-06-18","text":"Arreglos para CD en staging.","title":"0.0.2 (13-06-18)"},{"location":"HISTORY/#001-13-06-18","text":"Incorporaci\u00f3n de django_datajsonar con la posibilidad de modelar la red de nodos. Modelado de los nodos federadores y corridas de federaci\u00f3n. Posibilidad de correr federaciones desde la UI.","title":"0.0.1 (13-06-18)"},{"location":"arquitectura/","text":"Arquitectura La aplicaci\u00f3n de monitoreo-apertura est\u00e1 compuesta por un servidor solitario basado en Ubuntu 16.04 LTS que cumple con los siguientes roles: Servidor de aplicaciones python Servidor web Servidor de ejecuci\u00f3n de tareas asincr\u00f3nicas Servidor de bases de datos Servidor de aplicaciones python Este rol se implementa por medio de una aplicaci\u00f3n Python3 utilizando el framework web Django , instal\u00e1ndose todas las dependencias de la misma en un entorno virtual ( virtualenv ). La aplicaci\u00f3n python es ejecutada mediante el servicio gunicorn . Servidor web El servidor web de la soluci\u00f3n se implementa mediante una instalaci\u00f3n del servidor web de c\u00f3digo abierto nginx . La aplicaci\u00f3n web se expone en el puerto 80 del servidor web. Servidor de ejecuci\u00f3n de tareas asincr\u00f3nicas Las tareas asincr\u00f3nicas utilizan las mismas dependencias de la aplicaci\u00f3n web Django , pero se ejecuta como dos servicios distintos, basados en django-rq : rqworker : Uno o m\u00e1s procesos enncargados de la ejecuci\u00f3n de las tareas asincr\u00f3nicas solicitadas por la aplicaci\u00f3n web Django . rqscheduler : Este componente se encarga de disparar las tareas programadas peri\u00f3dicamente. Ambos servicios son utlizan el mismo entorno de ejecuci\u00f3n, entorno virtual ( virtualenv ) y la configuraci\u00f3n de la aplicaci\u00f3n Django . Servidor de bases de datos El rol de servidor de bases de datos es implementado mediante la configuraci\u00f3n de dos motores de bases de datos: PostgreSQL 9.6: Base de datos relacional. Utilizada por la aplicaci\u00f3n Django para Redis: Servidor de base de datos en memoria utilizado como administrador de mensajes para el sistema de ejecuci\u00f3n de tareas asincr\u00f3nicas. Diagrama de arquitectura","title":"Arquitectura"},{"location":"arquitectura/#arquitectura","text":"La aplicaci\u00f3n de monitoreo-apertura est\u00e1 compuesta por un servidor solitario basado en Ubuntu 16.04 LTS que cumple con los siguientes roles: Servidor de aplicaciones python Servidor web Servidor de ejecuci\u00f3n de tareas asincr\u00f3nicas Servidor de bases de datos","title":"Arquitectura"},{"location":"arquitectura/#servidor-de-aplicaciones-python","text":"Este rol se implementa por medio de una aplicaci\u00f3n Python3 utilizando el framework web Django , instal\u00e1ndose todas las dependencias de la misma en un entorno virtual ( virtualenv ). La aplicaci\u00f3n python es ejecutada mediante el servicio gunicorn .","title":"Servidor de aplicaciones python"},{"location":"arquitectura/#servidor-web","text":"El servidor web de la soluci\u00f3n se implementa mediante una instalaci\u00f3n del servidor web de c\u00f3digo abierto nginx . La aplicaci\u00f3n web se expone en el puerto 80 del servidor web.","title":"Servidor web"},{"location":"arquitectura/#servidor-de-ejecucion-de-tareas-asincronicas","text":"Las tareas asincr\u00f3nicas utilizan las mismas dependencias de la aplicaci\u00f3n web Django , pero se ejecuta como dos servicios distintos, basados en django-rq : rqworker : Uno o m\u00e1s procesos enncargados de la ejecuci\u00f3n de las tareas asincr\u00f3nicas solicitadas por la aplicaci\u00f3n web Django . rqscheduler : Este componente se encarga de disparar las tareas programadas peri\u00f3dicamente. Ambos servicios son utlizan el mismo entorno de ejecuci\u00f3n, entorno virtual ( virtualenv ) y la configuraci\u00f3n de la aplicaci\u00f3n Django .","title":"Servidor de ejecuci\u00f3n de tareas asincr\u00f3nicas"},{"location":"arquitectura/#servidor-de-bases-de-datos","text":"El rol de servidor de bases de datos es implementado mediante la configuraci\u00f3n de dos motores de bases de datos: PostgreSQL 9.6: Base de datos relacional. Utilizada por la aplicaci\u00f3n Django para Redis: Servidor de base de datos en memoria utilizado como administrador de mensajes para el sistema de ejecuci\u00f3n de tareas asincr\u00f3nicas.","title":"Servidor de bases de datos"},{"location":"arquitectura/#diagrama-de-arquitectura","text":"","title":"Diagrama de arquitectura"},{"location":"quick-start/","text":"Indice Comenzar a usar Monitoreo Apertura Comenzar a usar Monitoreo Apertura Esta secci\u00f3n deber\u00eda contener las primeras instrucciones en pasos numerados (inspirarse en https://datosgobar.github.io/series-tiempo-ar-api/quick-start/) para que el usuario pueda sin saber mucho hacer algo \u00fatil (cumplir con la funci\u00f3n m\u00e1s importante). Tiene el objetivo de que r\u00e1pidamente el usuario pueda estar usando la aplicaci\u00f3n.","title":"Comenzar a usar Monitoreo Apertura"},{"location":"quick-start/#indice","text":"Comenzar a usar Monitoreo Apertura","title":"Indice"},{"location":"quick-start/#comenzar-a-usar-monitoreo-apertura","text":"Esta secci\u00f3n deber\u00eda contener las primeras instrucciones en pasos numerados (inspirarse en https://datosgobar.github.io/series-tiempo-ar-api/quick-start/) para que el usuario pueda sin saber mucho hacer algo \u00fatil (cumplir con la funci\u00f3n m\u00e1s importante). Tiene el objetivo de que r\u00e1pidamente el usuario pueda estar usando la aplicaci\u00f3n.","title":"Comenzar a usar Monitoreo Apertura"},{"location":"usage/","text":"Indice Uso Carga de Nodos Configuraci\u00f3n de datasets indexables Generaci\u00f3n de archivos de configuraci\u00f3n Lectura de catalogos Lectura periodica Generaci\u00f3n de indicadores Reporte de indicadores Reporte de novedades Creaci\u00f3n de procesos Series de tiempo Importar/Exportar indicadores Modificar timezone de un Nodo Uso Carga de Nodos Despues de iniciar sesion como Administrador, debemos cargar un nuevo Node Register file . Esta pagina se encuentra en la ruta /admin/django_datajsonar/noderegisterfile/ . Este archivo tiene un registro de los nodos a federar . Ese un archivo de extencion .yml y tiene un aspecto como el siguiente: datosgobar : url : \"http://datos.gob.ar/data.json\" formato : \"json\" federado : false transporte-bis : url : \"http://datos.transporte.gob.ar/data.json\" formato : \"json\" federado : false # Mas nodos... Luego de que creamos la nueva instancia, volvemos a la pagina del listado y deberiamos ver algo como la siguiente imagen: Luego seleccionamos la instancia y usamos la accion \"Process node file\", como se muestra en la imagen: Eso procesara el archivo (puede tardar un poco), y al terminar veremos los nodos detectados en /admin/django_datajsonar/node/ , algo parecido a Configuraci\u00f3n de datasets indexables Hay 2 formas de marcar un nodo como indexable, manualmente o cargando un csv de configuraci\u00f3n. Para el caso manual, se puede marcar en el modelo, o marcar un subconjunto de los datasets y ejecutar la acci\u00f3n \"Marcar como indexable\". El otro m\u00e9todo es cargando un nuevo Dataset Indexing file . Esta pagina se encuentra en la ruta /admin/django_datajsonar/datasetindexingfile/ . El archivo tiene un registro de los datasets indexables . Es un archivo de extensi\u00f3n .csv y tiene un aspecto como el siguiente: catalog_id , dataset_identifier sspm , 399 sspm , 330 enacom , REGIS - DE - PROVE - POSTA acumar , cb351aa5 - 731 b - 458 b - 8227 - a0c5b828356f # M\u00e1s entradas La primera columna tiene el identificador del cat\u00e1logo, y la segunda el identificador del dataset que se desea marcar como indexable. Luego de que creamos la nueva instancia, volvemos a la p\u00e1gina del listado y deber\u00edamos ver algo como la siguiente imagen: Luego seleccionamos la instancia y usamos la acci\u00f3n \"Process node file\", como se muestra en la imagen: Eso procesa el archivo (puede tardar un poco), y al terminar veremos los datasets marcados como indexables en /admin/django_datajsonar/node/ . Generaci\u00f3n de archivos de configuraci\u00f3n Hay 2 formas de generar los archivos de configuraci\u00f3n con los datasets indexables. La primera es entrando en la ruta: admin/dataset/federacion-config.csv . De esa manera, se descarga un csv con todos datasets marcados como indexables. La segunda es mediante una acci\u00f3n de Django. Podemos seleccionar un subconjunto de datasets y ejecutar la acci\u00f3n Generar csv de configuraci\u00f3n De esta manera conseguimos el csv de configuraci\u00f3n con los datasets indexables del subconjunto elegido. Lectura de catalogos Para lanzar una lectura de todos los catalogos de los nodos, podemos instancia una ReadDataJsonTask . Para eso nos dirigimos a la ruta /admin/django_datajsonar/readdatajsontask/ . Esta instancia no requiere ningun parametro, ya que leera los datos necesarios de las instancias Node del proceso anterior. Esta instancia ira registrando los \"logs\" y \"resultados\" del proceso. Podremos ver algo como: Lectura periodica Para que la lectura de los catalogos se ejecute periodicamente, debemos crear un Synchronizer . En la vista de lista de Read Node Tasks podemos crear un nuevo synchronizer. Accediendo en la opci\u00f3n schedule task . Antes de guardar la instancia deberiamos tener algo como: En los campos del form podemos definir el horario a correr, los d\u00edas y el nombre del synchronizer. Generaci\u00f3n de indicadores Hay 2 formas de comenzar una corrida de generaci\u00f3n de indicadores de la red de nodos: podemos instanciar una Corrida de indicadores. Para eso nos dirigimos a la ruta /admin/dashboard/indicatorsgenerationtask/ . Esta instancia no requiere ningun parametro, lee los cat\u00e1logos a partir de la librer\u00eda de Github. Estas instancias registran los \"logs\" y \"resultados\" del proceso. Podremos ver algo como: La otra forma es mediante un management command de Django. El comando python manage.py indicadores dispara de manera sincr\u00f3nica una tarea de generaci\u00f3n de indicadores. De la misma manera que el anterior, el resultado se guarda en los logs del IndicatorsGenerationTask correspondiente. Reporte de indicadores Los mails de reporte de red se envian al staff del proyecto. Para marcar un usuario como staff, hay que acceder a la ruta /admin/auth/user/ y en la vista del usuario particular, marcar la opci\u00f3n: Es posible correr manualmente un proceso de env\u00edo de reportes instanciando un modelo de Django. Para eso nos dirigimos a la ruta /admin/dashboard/indicatorsgenerationtask/ . Esta instancia no requiere ningun par\u00e1metro, lee los indicadores calculados en la \u00faltima corrida de indicadores. Estas instancias registran los \"logs\" y \"resultados\" del proceso. Podremos ver algo como: Reporte de novedades Para hacer un reporte de novedades se puede crear el reporte manualmente (instanciando un modelo Django) o creando un proceso que generar\u00e1 reportes peri\u00f3dicamente creaci\u00f3n de procesos Si se quiere crear un reporte manualmente, vamos a /admin/dashboard/newlyreportgenerationtask/ y seleccionaremos Agregar Newly report generation task . Podremos ver el siguiente formulario: En este formulario solo tenemos que elegir sobre cual nodo haremos el reporte, o dejar el campo en blanco si queremos que se generenreportes de novedades sobre todos los nodos. Luego, se enviar\u00e1 un email a los administradores de cada nodo con la informaci\u00f3n de los datasets nuevos en ese nodo, as\u00ed como otro email al staff con la informaci\u00f3n de todos los datasets nuevos. IMPORTANTE: Un nuevo reporte de novedades se fija cu\u00e1ndo se hizo el \u00faltimo reporte para determinar los datasets que son nuevos. Es por esto que el primer task de reporte de novedades creado NO generar\u00e1 ning\u00fan reporte. Creaci\u00f3n de procesos Es posible, crear procesos que engloben las tareas descriptas anteriormente y las ejecuten secuencialmente. Para lograr eso vamos a la ruta /admin/django_datajsonar/synchronizer/ . All\u00ed vamos a Agregar synchronizer y nos encontramos con un formulario de este estilo: El campo name identifica al synchronizer, frequency determina los d\u00edas cuando se correr\u00e1n los procesos. Finalmente, scheduled time indica la hora a correr la primer etapa del synchronizer. Cada fila del campo task representa una etapa, y se ejecutan en orden siendo la de arriba la primera. Actualmente, para configurar las tareas ya existentes, se pueden pasar los siguientes procesos: - Read Datajson ( complete ) - Read Datajson ( metadata only ) - Federation - Indicators - Indicators reports - Validation reports Series de tiempo Es posible descargar los indicadores como series de tiempo en formato .csv . Entrando en la ruta admin/dashboard/indicadorred/series-indicadores podemos descargar las series de los indicadores agregados; y en la ruta admin/dashboard/indicador/<id de nodo>/series-indicadores se encuentran las series para nodos particulares. Se pueden definir en el admin de tipos de indicadores cuales se desean mostrar en las series. Marcando los booleanos, series red y series nodos se especifican los tipos a presentar. Importar/Exportar indicadores Se pueden bajar la base de indicadores e indicadores de red mediante el management command: /manage.py export_indicators [file] [--aggregated] . El argumento file es un path al archivo donde se van a escribir los indicadores. El parametro opcional --aggregated indica si se trata de indicadores red, por default se asume indicadores de nodos. A su vez es posible importar a la base de indicadores mediante el management command /manage.py import_indicators [file] [--aggregated] Los par\u00e1metros file y --aggregated indican lo mismo que para el comando anterior. Se espera un csv v\u00e1lido con la forma: fecha, indicador_tipo, indicador_valor [, jurisdiccion_id, jurisdiccion_nombre] para indicadores de red y de nodos respectivamente. La operaci\u00f3n es un upsert, es decir se actualizaran los valores en caso que ya existen y se crearan indicadores nuevos si estos no est\u00e1n presentes. Alternativamente, se puede importar mediante UI un csv con los indicadores ( Importante : el csv debe tener la misma forma que el descripto por el punto anterior). Desde la vista de lista de la tabla de indicadores correspondientes, se ingresa con el bot\u00f3n importar. Deber\u00eda caer al siguiente form: El primer campo toma el archivo de csv a subir; el segundo, el formato del archivo. Actualmente, el \u00fanico formato que acepta es csv. Adem\u00e1s, accediendo a las siguientes rutas, se pueden descargar los siguientes dumps: /indicadores-red.csv : descarga un dump de la base de indicadores de red en formato.csv /indicadores-nodo.csv : descarga un dump de los indicadores de nodos /indicadores-federadores.csv : descarga un dump de los indicadores federadores /nodos.json : devuelve (no descarga) la informaci\u00f3n de todos los nodos (id y nombre de los nodos, nombre de jurisdicci\u00f3n, urls de descarga de datos, etc). Se puede descargar esta informaci\u00f3n en formato csv o xlsx accediendo a /nodos.csv o /nodos.xlsx respectivamente /nodes.json : idem al url anterior, pero con los datos en ingl\u00e9s. Tambi\u00e9n se pueden descargar en formatos csv o xlsx cambiando la extension de archivo en el url /distribuciones.csv : descarga un dump con toda la informaci\u00f3n de las distribuciones /admin/django_datajsonar/dataset/federacion-config.csv : descarga un dump con los identificadores de los DataSets y la id del cat\u00e1logo al que pertenecen /admin/dashboard/indicadorred/series-indicadores : descarga un archivo csv con informaci\u00f3n sobre todos los datasets Modificar timezone de un Nodo Es posible modificar el timezone de un nodo si as\u00ed se deseara o en caso de que sea necesario. Para esto, simplemente cambiamos el campo Timezone cuando creamos un nuevo nodo federador en /admin/dashboard/harvestingnode/add/ , o bien un nodo en django_datajsonar en /admin/django_datajsonar/node/add/ . Por defecto, el timezone es 'America/Buenos_Aires'. Aqu\u00ed se puede consultar una lista completa de los timezones que pueden usarse (columna TZ database name ).","title":"Manual de uso"},{"location":"usage/#indice","text":"Uso Carga de Nodos Configuraci\u00f3n de datasets indexables Generaci\u00f3n de archivos de configuraci\u00f3n Lectura de catalogos Lectura periodica Generaci\u00f3n de indicadores Reporte de indicadores Reporte de novedades Creaci\u00f3n de procesos Series de tiempo Importar/Exportar indicadores Modificar timezone de un Nodo","title":"Indice"},{"location":"usage/#uso","text":"","title":"Uso"},{"location":"usage/#carga-de-nodos","text":"Despues de iniciar sesion como Administrador, debemos cargar un nuevo Node Register file . Esta pagina se encuentra en la ruta /admin/django_datajsonar/noderegisterfile/ . Este archivo tiene un registro de los nodos a federar . Ese un archivo de extencion .yml y tiene un aspecto como el siguiente: datosgobar : url : \"http://datos.gob.ar/data.json\" formato : \"json\" federado : false transporte-bis : url : \"http://datos.transporte.gob.ar/data.json\" formato : \"json\" federado : false # Mas nodos... Luego de que creamos la nueva instancia, volvemos a la pagina del listado y deberiamos ver algo como la siguiente imagen: Luego seleccionamos la instancia y usamos la accion \"Process node file\", como se muestra en la imagen: Eso procesara el archivo (puede tardar un poco), y al terminar veremos los nodos detectados en /admin/django_datajsonar/node/ , algo parecido a","title":"Carga de Nodos"},{"location":"usage/#configuracion-de-datasets-indexables","text":"Hay 2 formas de marcar un nodo como indexable, manualmente o cargando un csv de configuraci\u00f3n. Para el caso manual, se puede marcar en el modelo, o marcar un subconjunto de los datasets y ejecutar la acci\u00f3n \"Marcar como indexable\". El otro m\u00e9todo es cargando un nuevo Dataset Indexing file . Esta pagina se encuentra en la ruta /admin/django_datajsonar/datasetindexingfile/ . El archivo tiene un registro de los datasets indexables . Es un archivo de extensi\u00f3n .csv y tiene un aspecto como el siguiente: catalog_id , dataset_identifier sspm , 399 sspm , 330 enacom , REGIS - DE - PROVE - POSTA acumar , cb351aa5 - 731 b - 458 b - 8227 - a0c5b828356f # M\u00e1s entradas La primera columna tiene el identificador del cat\u00e1logo, y la segunda el identificador del dataset que se desea marcar como indexable. Luego de que creamos la nueva instancia, volvemos a la p\u00e1gina del listado y deber\u00edamos ver algo como la siguiente imagen: Luego seleccionamos la instancia y usamos la acci\u00f3n \"Process node file\", como se muestra en la imagen: Eso procesa el archivo (puede tardar un poco), y al terminar veremos los datasets marcados como indexables en /admin/django_datajsonar/node/ .","title":"Configuraci\u00f3n de datasets indexables"},{"location":"usage/#generacion-de-archivos-de-configuracion","text":"Hay 2 formas de generar los archivos de configuraci\u00f3n con los datasets indexables. La primera es entrando en la ruta: admin/dataset/federacion-config.csv . De esa manera, se descarga un csv con todos datasets marcados como indexables. La segunda es mediante una acci\u00f3n de Django. Podemos seleccionar un subconjunto de datasets y ejecutar la acci\u00f3n Generar csv de configuraci\u00f3n De esta manera conseguimos el csv de configuraci\u00f3n con los datasets indexables del subconjunto elegido.","title":"Generaci\u00f3n de archivos de configuraci\u00f3n"},{"location":"usage/#lectura-de-catalogos","text":"Para lanzar una lectura de todos los catalogos de los nodos, podemos instancia una ReadDataJsonTask . Para eso nos dirigimos a la ruta /admin/django_datajsonar/readdatajsontask/ . Esta instancia no requiere ningun parametro, ya que leera los datos necesarios de las instancias Node del proceso anterior. Esta instancia ira registrando los \"logs\" y \"resultados\" del proceso. Podremos ver algo como:","title":"Lectura de catalogos"},{"location":"usage/#lectura-periodica","text":"Para que la lectura de los catalogos se ejecute periodicamente, debemos crear un Synchronizer . En la vista de lista de Read Node Tasks podemos crear un nuevo synchronizer. Accediendo en la opci\u00f3n schedule task . Antes de guardar la instancia deberiamos tener algo como: En los campos del form podemos definir el horario a correr, los d\u00edas y el nombre del synchronizer.","title":"Lectura periodica"},{"location":"usage/#generacion-de-indicadores","text":"Hay 2 formas de comenzar una corrida de generaci\u00f3n de indicadores de la red de nodos: podemos instanciar una Corrida de indicadores. Para eso nos dirigimos a la ruta /admin/dashboard/indicatorsgenerationtask/ . Esta instancia no requiere ningun parametro, lee los cat\u00e1logos a partir de la librer\u00eda de Github. Estas instancias registran los \"logs\" y \"resultados\" del proceso. Podremos ver algo como: La otra forma es mediante un management command de Django. El comando python manage.py indicadores dispara de manera sincr\u00f3nica una tarea de generaci\u00f3n de indicadores. De la misma manera que el anterior, el resultado se guarda en los logs del IndicatorsGenerationTask correspondiente.","title":"Generaci\u00f3n de indicadores"},{"location":"usage/#reporte-de-indicadores","text":"Los mails de reporte de red se envian al staff del proyecto. Para marcar un usuario como staff, hay que acceder a la ruta /admin/auth/user/ y en la vista del usuario particular, marcar la opci\u00f3n: Es posible correr manualmente un proceso de env\u00edo de reportes instanciando un modelo de Django. Para eso nos dirigimos a la ruta /admin/dashboard/indicatorsgenerationtask/ . Esta instancia no requiere ningun par\u00e1metro, lee los indicadores calculados en la \u00faltima corrida de indicadores. Estas instancias registran los \"logs\" y \"resultados\" del proceso. Podremos ver algo como:","title":"Reporte de indicadores"},{"location":"usage/#reporte-de-novedades","text":"Para hacer un reporte de novedades se puede crear el reporte manualmente (instanciando un modelo Django) o creando un proceso que generar\u00e1 reportes peri\u00f3dicamente creaci\u00f3n de procesos Si se quiere crear un reporte manualmente, vamos a /admin/dashboard/newlyreportgenerationtask/ y seleccionaremos Agregar Newly report generation task . Podremos ver el siguiente formulario: En este formulario solo tenemos que elegir sobre cual nodo haremos el reporte, o dejar el campo en blanco si queremos que se generenreportes de novedades sobre todos los nodos. Luego, se enviar\u00e1 un email a los administradores de cada nodo con la informaci\u00f3n de los datasets nuevos en ese nodo, as\u00ed como otro email al staff con la informaci\u00f3n de todos los datasets nuevos. IMPORTANTE: Un nuevo reporte de novedades se fija cu\u00e1ndo se hizo el \u00faltimo reporte para determinar los datasets que son nuevos. Es por esto que el primer task de reporte de novedades creado NO generar\u00e1 ning\u00fan reporte.","title":"Reporte de novedades"},{"location":"usage/#creacion-de-procesos","text":"Es posible, crear procesos que engloben las tareas descriptas anteriormente y las ejecuten secuencialmente. Para lograr eso vamos a la ruta /admin/django_datajsonar/synchronizer/ . All\u00ed vamos a Agregar synchronizer y nos encontramos con un formulario de este estilo: El campo name identifica al synchronizer, frequency determina los d\u00edas cuando se correr\u00e1n los procesos. Finalmente, scheduled time indica la hora a correr la primer etapa del synchronizer. Cada fila del campo task representa una etapa, y se ejecutan en orden siendo la de arriba la primera. Actualmente, para configurar las tareas ya existentes, se pueden pasar los siguientes procesos: - Read Datajson ( complete ) - Read Datajson ( metadata only ) - Federation - Indicators - Indicators reports - Validation reports","title":"Creaci\u00f3n de procesos"},{"location":"usage/#series-de-tiempo","text":"Es posible descargar los indicadores como series de tiempo en formato .csv . Entrando en la ruta admin/dashboard/indicadorred/series-indicadores podemos descargar las series de los indicadores agregados; y en la ruta admin/dashboard/indicador/<id de nodo>/series-indicadores se encuentran las series para nodos particulares. Se pueden definir en el admin de tipos de indicadores cuales se desean mostrar en las series. Marcando los booleanos, series red y series nodos se especifican los tipos a presentar.","title":"Series de tiempo"},{"location":"usage/#importarexportar-indicadores","text":"Se pueden bajar la base de indicadores e indicadores de red mediante el management command: /manage.py export_indicators [file] [--aggregated] . El argumento file es un path al archivo donde se van a escribir los indicadores. El parametro opcional --aggregated indica si se trata de indicadores red, por default se asume indicadores de nodos. A su vez es posible importar a la base de indicadores mediante el management command /manage.py import_indicators [file] [--aggregated] Los par\u00e1metros file y --aggregated indican lo mismo que para el comando anterior. Se espera un csv v\u00e1lido con la forma: fecha, indicador_tipo, indicador_valor [, jurisdiccion_id, jurisdiccion_nombre] para indicadores de red y de nodos respectivamente. La operaci\u00f3n es un upsert, es decir se actualizaran los valores en caso que ya existen y se crearan indicadores nuevos si estos no est\u00e1n presentes. Alternativamente, se puede importar mediante UI un csv con los indicadores ( Importante : el csv debe tener la misma forma que el descripto por el punto anterior). Desde la vista de lista de la tabla de indicadores correspondientes, se ingresa con el bot\u00f3n importar. Deber\u00eda caer al siguiente form: El primer campo toma el archivo de csv a subir; el segundo, el formato del archivo. Actualmente, el \u00fanico formato que acepta es csv. Adem\u00e1s, accediendo a las siguientes rutas, se pueden descargar los siguientes dumps: /indicadores-red.csv : descarga un dump de la base de indicadores de red en formato.csv /indicadores-nodo.csv : descarga un dump de los indicadores de nodos /indicadores-federadores.csv : descarga un dump de los indicadores federadores /nodos.json : devuelve (no descarga) la informaci\u00f3n de todos los nodos (id y nombre de los nodos, nombre de jurisdicci\u00f3n, urls de descarga de datos, etc). Se puede descargar esta informaci\u00f3n en formato csv o xlsx accediendo a /nodos.csv o /nodos.xlsx respectivamente /nodes.json : idem al url anterior, pero con los datos en ingl\u00e9s. Tambi\u00e9n se pueden descargar en formatos csv o xlsx cambiando la extension de archivo en el url /distribuciones.csv : descarga un dump con toda la informaci\u00f3n de las distribuciones /admin/django_datajsonar/dataset/federacion-config.csv : descarga un dump con los identificadores de los DataSets y la id del cat\u00e1logo al que pertenecen /admin/dashboard/indicadorred/series-indicadores : descarga un archivo csv con informaci\u00f3n sobre todos los datasets","title":"Importar/Exportar indicadores"},{"location":"usage/#modificar-timezone-de-un-nodo","text":"Es posible modificar el timezone de un nodo si as\u00ed se deseara o en caso de que sea necesario. Para esto, simplemente cambiamos el campo Timezone cuando creamos un nuevo nodo federador en /admin/dashboard/harvestingnode/add/ , o bien un nodo en django_datajsonar en /admin/django_datajsonar/node/add/ . Por defecto, el timezone es 'America/Buenos_Aires'. Aqu\u00ed se puede consultar una lista completa de los timezones que pueden usarse (columna TZ database name ).","title":"Modificar timezone de un Nodo"},{"location":"developers/development/","text":"","title":"Desarrollo"},{"location":"developers/install/","text":"","title":"Instalaci\u00f3n"},{"location":"developers/tests/","text":"","title":"Tests"},{"location":"developers/update/","text":"","title":"Actualizaci\u00f3n"}]}